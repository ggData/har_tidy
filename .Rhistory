code_book = './data/wk4_q1_code_book.pdf'
safe.download(url, code_book, method='curl')
data = fread(data_path)
View(data)
names(data)
strsplit(names(data), split='wgtp')
strsplit(names(data), split='wgtp')[15]
strsplit(names(data), split='wgtp')[123]
library(data.table)
# ensure we have a data folder
if(!file.exists("./data")){dir.create("./data")}
safe.download = function(url, dest, replace=FALSE, method='auto') {
# @ url: of file to download
# @ dest: pathname to destination file
# @ replace: set to TRUE if to over-write existing file
# @ method: can also be 'curl', 'wget', or 'lynx'
if (!replace & file.exists(dest)) {
return(TRUE)
}
download.file(url, dest, method)
}
# download data
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
gdp_path = './data/wk4_q2_GDP.csv'
safe.download(url, gdp_path, method='curl')
gdp = fread(gdp_path, select=c(1,2,4,5))
gdp = gdp[1:190]
names(gdp) = c('CountryCode', 'Ranking', 'Long_Name', 'USD')
View(gdp)
sub(',', '', gdp[USD])
sub(',', '', gdp[,USD])
gsub(',', '', gdp[,USD])
as.integer(gsub(',', '', gdp[,USD]))
View(gdp)
# download data
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
gdp_path = './data/wk4_q2_GDP.csv'
safe.download(url, gdp_path, method='curl')
gdp = fread(gdp_path, select=c(1,2,4,5))
gdp = gdp[1:190]
names(gdp) = c('CountryCode', 'Ranking', 'Long_Name', 'USD')
gdp[USD] = gsub(',', '', gdp[,USD])  # remove commas
gdp[USD] = as.numeric(gdp[USD])  # convert to number
mean(gdp[USD])
mean(gdp[,USD])
View(gdp)
gdp[USD] = gsub(',', '', gdp[,USD])  # remove commas
gdp$USD = gsub(',', '', gdp[,USD])  # remove commas
View(gdp)
gdp$USD = as.numeric(gdp[USD])  # convert to number
gdp$USD = as.numeric(gdp[,USD])  # convert to number
mean(gdp[,USD])
View(gdp)
grep("^United",gdp$Long_NAME)
grep("^United",gdp$Long_Name)
length(grep("^United",gdp$Long_Name))
length(grep("*United",gdp$Long_Name))
length(grep("United$",gdp$Long_Name))
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
gdp_path = './data/wk4_q4_GDP.csv'
safe.download(url, gdp_path, method='curl')
gdp = fread(gdp_path)
View(gdp)
gdp = fread(gdp_path, colClasses='character')
gdp = gdp[1:190]
View(gdp)
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
educ_path = './data/wk3_q3_educ.csv'  # same as previous week
safe.download(url, educ_path, method='curl')
educ = fread(educ_path)
setkey(educ, CountryCode)  # key also by country code
View(educ)
# download GDP data
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
gdp_path = './data/wk4_q4_GDP.csv'
safe.download(url, gdp_path, method='curl')
gdp = fread(gdp_path, colClasses='character')
gdp = gdp[1:190]
names(gdp) = c('CountryCode', 'Ranking', 'Long_Name', 'USD')
# download GDP data
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
gdp_path = './data/wk4_q4_GDP.csv'
safe.download(url, gdp_path, method='curl')
gdp = fread(gdp_path, select=c(1,2,4,5))
gdp = gdp[1:190]
names(gdp) = c('CountryCode', 'Ranking', 'Long_Name', 'USD')
View(gdp)
# download educ data
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
educ_path = './data/wk3_q3_educ.csv'  # same as previous week
safe.download(url, educ_path, method='curl')
educ = fread(educ_path, select=c(1,10))
setkey(educ, CountryCode)  # key also by country code
View(educ)
tables()  # have a look at what data tables we have now
data = merge(educ, gdp, by.x=CountryCode, by.y=CountryCode)
View(data)
length(grep('^Fiscal year end: June', data[]))
length(grep('^Fiscal year end: June', data[, 'Special Notes]))
length(grep('^Fiscal year end: June', data[, 'Special Notes']))
length(grep('^Fiscal year end: June', data[, 'Special Notes']))
length(grep('^Fiscal year end: June', data[, 2, with=FALSE]))
data[,2]
data[,'Special Notes']
data[,2, with=FALSE]
length(grep('Fiscal year end: June', data[, 2, with=FALSE]))
length(grep('Fiscal year end\: June', data[, 2, with=FALSE]))
length(grep('June', data[, 2, with=FALSE]))
length(data[,2, with=FALSE])
class(data[,2, with=FALSE])
length(grep('*June', data[, 2, with=FALSE]))
grep('*June', data[, 2, with=FALSE])
class(data[,2, with=FALSE])
as.list(data[,2, with=FALSE])
notes = as.list(data[,2, with=FALSE])
grep('*June',notes)
grep('^Fiscal year end: June',notes)
table(grep('^Fiscal year end: June',notes))
table(grep('Fiscal year end: June',notes))
table(grepl('Fiscal year end: June',notes))
table(grepl('Fiscal year end: June.*',notes))
notes
install.packages("quantmod")
library(data.table)
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
View(amzn)
View(amzn)
sampleTimes
grepl('^2012', sampleTimes)
sum(grepl('^2012', sampleTimes))
install.packages("lubridate")
library(data.table)
library(quantmod)
library(lubridate)
sampleTimes = ymd(sampleTimes)
head(sampleTimes)
sampleTimes$weekday = wday(ymd(sampleTimes))
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes = data.table(times = sampleTimes)
View(sampleTimes)
sampleTimes$weekday = wday(ymd(sampleTimes))
View(sampleTimes)
sampleTimes$weekday = wday(ymd(sampleTimes$times))
View(sampleTimes)
sampleTimes$weekday = wday(ymd(sampleTimes$times), label=TRUE)
View(sampleTimes)
sampleTimes$year = year(sampleTimes$times)
View(sampleTimes)
sampleTimes[weekday=='Mon']
sampleTimes[weekday=='Mon' & year=='2012']
nrow(sampleTimes[weekday=='Mon' & year=='2012'])
library(data.table)
library(quantmod)
library(lubridate)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = data.table(times = index(amzn))
sampleTimes$weekday = wday(ymd(sampleTimes$times), label=TRUE)
sampleTimes$year = year(sampleTimes$times)
nrow(sampleTimes[year=='2012'])
nrow(sampleTimes[weekday=='Mon' & year=='2012'])
library(data.table)
library(quantmod)
library(lubridate)
# download GDP data
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
gdp_path = './data/wk4_q4_GDP.csv'
safe.download(url, gdp_path, method='curl')
gdp = fread(gdp_path, select=c(1,2,4,5))
gdp = gdp[1:190]
names(gdp) = c('CountryCode', 'Ranking', 'Long_Name', 'USD')
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
# download educ data
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
educ_path = './data/wk3_q3_educ.csv'  # same as previous week
safe.download(url, educ_path, method='curl')
educ = fread(educ_path, select=c(1,10))
setkey(educ, CountryCode)  # key also by country code
library(data.table)
library(quantmod)
library(lubridate)
# ensure we have a data folder
if(!file.exists("./data")){dir.create("./data")}
safe.download = function(url, dest, replace=FALSE, method='auto') {
# @ url: of file to download
# @ dest: pathname to destination file
# @ replace: set to TRUE if to over-write existing file
# @ method: can also be 'curl', 'wget', or 'lynx'
if (!replace & file.exists(dest)) {
return(TRUE)
}
download.file(url, dest, method)
}
# download GDP data
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
gdp_path = './data/wk4_q4_GDP.csv'
safe.download(url, gdp_path, method='curl')
gdp = fread(gdp_path, select=c(1,2,4,5))
gdp = gdp[1:190]
names(gdp) = c('CountryCode', 'Ranking', 'Long_Name', 'USD')
# download educ data
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
educ_path = './data/wk3_q3_educ.csv'  # same as previous week
safe.download(url, educ_path, method='curl')
educ = fread(educ_path, select=c(1,10))
setkey(educ, CountryCode)  # key also by country code
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
gdp_path = './data/wk4_q4_GDP.csv'
safe.download(url, gdp_path, method='curl')
gdp = fread(gdp_path, select=c(1,2,4,5))
gdp = gdp[1:190]
new_names = c('CountryCode', 'Ranking', 'Long_Name', 'USD')
setnames(gdp,names(gdp),new_names)
View(gdp)
# download educ data
url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
educ_path = './data/wk3_q3_educ.csv'  # same as previous week
safe.download(url, educ_path, method='curl')
educ = fread(educ_path, select=c(1,10))
setkey(educ, CountryCode)  # key also by country code
data = merge(educ, gdp, by.x=CountryCode, by.y=CountryCode)
View(data)
data = merge(educ, gdp, by.x=CountryCode, by.y=CountryCode)
setnames(data,
c('CountryCode', 'Special Notes'),
c('Country_Code', 'Special_Notes'))
View(data)
table(grepl('^Fiscal year end: June.*',data$Special_Notes))
setwd("~/dev/coursera/Getting and Cleaning Data/peer_assessment")
basename(file.path("","p1","p2","p3", c("file1", "file2")))
dirname(file.path("","p1","p2","p3","filename"))
BASE_DIR = dirname(file.path('.', 'UCI HAR Dataset'))
BASE_DIR = file.path('.', 'UCI HAR Dataset')
TEST_DIR = file.path(BASE_DIR, 'test')
TRAIN_DIR = file.path(BASE_DIR, 'train')
DATA_URL = 'http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones'
DATA_FILE = 'getdata-projectfiles-UCI HAR Dataset.zip'
install.packages("unzip")
unz('file.zip')
unz(DATA_FILE)
getwd()
ls
ls()
data <- read.table(unz(DATA_FILE, "features.txt"))
data <- read.table(unz(DATA_FILE, "UCI HAR Dataset/features.txt"))
View(data)
View(data)
data <- read.table(unz(DATA_FILE, file.path(BASE_DIR, "features.txt"))
)
BASE_DIR = 'UCI HAR Dataset'
)
data <- read.table(unz(DATA_FILE, file.path(BASE_DIR, "features.txt")))
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
DATA_DIR = file.path('.', 'data')
source('~/.active-rstudio-document', echo=TRUE)
features = fread(unz(DATA_FILE, file.path(BASE_DIR, 'features.txt')))
features = read.table(unz(DATA_FILE, file.path(BASE_DIR, 'features.txt')))
View(features)
class(features)
View(features)
activity_labels = read.table(unz(DATA_FILE, file.path(BASE_DIR, 'activity_labels.txt')))
View(activity_labels)
subject = read.table(unz(DATA_FILE, file.path(TEST_DIR, 'subject_test.txt')))
View(subject)
subject = read.table(unz(DATA_FILE, file.path(TEST_DIR, 'subject_test.txt')))
X = read.table(unz(DATA_FILE, file.path(TEST_DIR, 'X_test.txt')))
y = read.table(unz(DATA_FILE, file.path(TEST_DIR, 'y_test.txt')))
source('~/.active-rstudio-document', echo=TRUE)
names(X) = features[,2]
View(X)
View(y)
View(activity_labels)
y$activity = cut(y$V1, breaks = activity_labels$V1, labels = activity_labels$V2)
activity_labels$V1
activity_labels$V2
length(activity_labels$V2)
length(activity_labels$V1)
y$V1
unique(y$V1)
cut(y$V1, 6)
y$activity = sapply(y$V1, function(x) activity_labels[x,'V2'])
View(y)
summary(y)
View(features)
mean_std_cols = grepl(pattern='mean\(\)|std\(\)',features$V2)
mean_std_cols = grepl(pattern='mean()|std()',features$V2)
mean_std_cols
table(mean_std_cols)
mean_std_cols = grep(pattern='mean()|std()',features$V2)
mean_std_cols = features$V2[grep(pattern='mean()|std()',features$V2)]
mean_std_cols = as.character(features$V2[grep(pattern='mean()|std()',features$V2)])
mean_std_cols
subject = read.table(unz(DATA_FILE, file.path(TEST_DIR, 'subject_test.txt')))
X = read.table(unz(DATA_FILE, file.path(TEST_DIR, 'X_test.txt')))
names(X) = features[,2]
X = X[,mean_std_cols]
View(X)
subject = read.table(unz(DATA_FILE, file.path(TEST_DIR, 'subject_test.txt')))
X = read.table(unz(DATA_FILE, file.path(TEST_DIR, 'X_test.txt')))
names(X) = features[,2]
X = X[,mean_std_cols]
y = read.table(unz(DATA_FILE, file.path(TEST_DIR, 'y_test.txt')))
y$activity = sapply(y$V1, function(x) activity_labels[x,'V2'])
data_test = data.table(id = subject,
activity = y$activity)
View(data_test)
View(subject)
data_test = data.table(id = subject$V1,
activity = y$activity)
View(data_test)
data_test = data.table(id = subject$V1,
activity = y$activity,
set = 'test')
View(data_test)
data_test = cbind(data_test, X)
View(data_test)
set = 'test'
paste('subject_', set, '.txt')
paste0('subject_', set, '.txt')
library(data.table)
BASE_DIR = 'UCI HAR Dataset'
TEST_DIR = file.path(BASE_DIR, 'test')
TRAIN_DIR = file.path(BASE_DIR, 'train')
DATA_URL = 'https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip'
DATA_FILE = 'getdata-projectfiles-UCI HAR Dataset.zip'
DATA_DIR = file.path('.', 'data')
# function to download to destination file with or without replacement
safe.download = function(url, dest, replace=FALSE, method='auto') {
# @ url: of file to download
# @ dest: pathname to destination file
# @ replace: set to TRUE if to over-write existing file
# @ method: can also be 'curl', 'wget', or 'lynx'
if (!replace & file.exists(dest)) {
return(TRUE)
}
download.file(url, dest, method)
}
# ensure we have data here
if(!file.exists(file.path('.', DATA_FILE))){
safe.download(DATA_URL, DATA_FILE, method='curl')
}
# and ensure data folder for our results
if(!file.exists(DATA_DIR)){
dir.create(DATA_DIR)
}
features = read.table(unz(DATA_FILE, file.path(BASE_DIR, 'features.txt')))
mean_std_cols = as.character(features$V2[grep(pattern='mean()|std()',features$V2)])
activity_labels = read.table(unz(DATA_FILE, file.path(BASE_DIR, 'activity_labels.txt')))
extract = function(set='test') {
subject_filename = paste0('subject_', set, '.txt')
X_filename = paste0('X_', set, '.txt')
y_filename = paste0('y_', set, '.txt')
if (set=='test') {
DIR = TEST_DIR
} else {
DIR = TRAIN_DIR
}
subject = read.table(unz(DATA_FILE, file.path(DIR, subject_filename)))
X = read.table(unz(DATA_FILE, file.path(DIR, X_filename)))
names(X) = features[,2]
X = X[,mean_std_cols]
y = read.table(unz(DATA_FILE, file.path(DIR, y_filename)))
y$activity = sapply(y$V1, function(x) activity_labels[x,'V2'])
data = data.table(subject = subject$V1,
activity = y$activity,
set = set)
data = cbind(data_test, X)
return(data)
}
test_data = extract(set='test')
train_data = extract(set='train')
test_data = extract(set='test')
train_data = extract(set='train')
library(data.table)
BASE_DIR = 'UCI HAR Dataset'
TEST_DIR = file.path(BASE_DIR, 'test')
TRAIN_DIR = file.path(BASE_DIR, 'train')
DATA_URL = 'https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip'
DATA_FILE = 'getdata-projectfiles-UCI HAR Dataset.zip'
DATA_DIR = file.path('.', 'data')
# function to download to destination file with or without replacement
safe.download = function(url, dest, replace=FALSE, method='auto') {
# @ url: of file to download
# @ dest: pathname to destination file
# @ replace: set to TRUE if to over-write existing file
# @ method: can also be 'curl', 'wget', or 'lynx'
if (!replace & file.exists(dest)) {
return(TRUE)
}
download.file(url, dest, method)
}
# ensure we have data here
if(!file.exists(file.path('.', DATA_FILE))){
safe.download(DATA_URL, DATA_FILE, method='curl')
}
# and ensure data folder for our results
if(!file.exists(DATA_DIR)){
dir.create(DATA_DIR)
}
features = read.table(unz(DATA_FILE, file.path(BASE_DIR, 'features.txt')))
mean_std_cols = as.character(features$V2[grep(pattern='mean()|std()',features$V2)])
activity_labels = read.table(unz(DATA_FILE, file.path(BASE_DIR, 'activity_labels.txt')))
extract = function(set='test') {
subject_filename = paste0('subject_', set, '.txt')
X_filename = paste0('X_', set, '.txt')
y_filename = paste0('y_', set, '.txt')
if (set=='test') {
DIR = TEST_DIR
} else {
DIR = TRAIN_DIR
}
subject = read.table(unz(DATA_FILE,
file.path(DIR, subject_filename)))
X = read.table(unz(DATA_FILE,
file.path(DIR, X_filename)))
names(X) = features[,2]
X = X[,mean_std_cols]
y = read.table(unz(DATA_FILE,
file.path(DIR, y_filename)))
y$activity = sapply(y$V1, function(x) activity_labels[x,'V2'])
data = data.table(subject = subject$V1,
activity = y$activity,
set = set)
data = cbind(data, X)
return(data)
}
test_data = extract(set='test')
train_data = extract(set='train')
full_data = rbind(test_data, train_data)
View(full_data)
full_data = rbind(test_data, train_data)
head(full_data, 2)
tail(full_data, 2)
full_data[1:5, 1:4]
source('~/.active-rstudio-document', echo=TRUE)
MERGED_DATA = file.path(DATA_DIR, 'full_data.Rdata')
save(full_data, file=MERGED_DATA)
load("/Users/gauden/dev/coursera/Getting and Cleaning Data/peer_assessment/data/full_data.Rdata")
class(full_data)
names(full_data)[1:5]
cols = names(full_data)
cols
cols = as.character(cols[grep(pattern='mean()',cols)])
cols
cols = names(full_data)
which(cols, arr.ind=grep(pattern='mean()',cols))
which(cols, arr.ind=grepl(pattern='mean()',cols))
class(cols)
tidy_data = full_data[,c('subject', 'activity'), with=FALSE]
View(tidy_data)
tidy_data = full_data[,c('subject', 'activity', cols), with=FALSE]
View(train_data)
cols = names(full_data)
cols = as.character(cols[grep(pattern='mean()',cols)])
tidy_data = full_data[,c('subject', 'activity', cols), with=FALSE]
View(tidy_data)
mean_cols = names(full_data)
mean_cols = as.character(mean_cols[grep(pattern='mean()',mean_cols)])
tidy_data = full_data[,c('subject', 'activity', mean_cols), with=FALSE]
tidy_data = full_data[,c('subject', 'activity', mean_cols), with=TRUE]
tidy_data = full_data[,c('subject', 'activity', mean_cols), with=FALSE]
install.packages("reshape2")
library(reshape2)
library(data.table)
library(reshape2)
source('~/.active-rstudio-document', echo=TRUE)
melt(tidy_data, id=c('subject', 'activity'))
getwd()
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
View(tidy_data)
purl('run_analysis.Rmd')
library(knitr)
purl('run_analysis.Rmd')
source('run_analysis.R')
source('~/.active-rstudio-document', echo=TRUE)
full_data = rbind(test_data, train_data)
save(full_data, file=MERGED_DATA)
write.table(full_data, file=MERGED_DATA_TXT, sep=',')
mean_cols = names(full_data)
mean_cols = as.character(mean_cols[grep(pattern='mean()',mean_cols)])
tidy_data = full_data[,c('subject', 'activity', mean_cols), with=FALSE]
tidy_data = melt(tidy_data, id=c('subject', 'activity'))
save(tidy_data, file=TIDY_DATA)
write.table(tidy_data, file=TIDY_DATA_TXT, sep=',')
full_data = rbind(test_data, train_data)
save(full_data, file=MERGED_DATA)
write.table(full_data, file=MERGED_DATA_TXT, sep=',', row.names = FALSE)
mean_cols = names(full_data)
mean_cols = as.character(mean_cols[grep(pattern='mean()',mean_cols)])
tidy_data = full_data[,c('subject', 'activity', mean_cols), with=FALSE]
tidy_data = melt(tidy_data, id=c('subject', 'activity'))
save(tidy_data, file=TIDY_DATA)
write.table(tidy_data, file=TIDY_DATA_TXT, sep=',', row.names = FALSE)
full_data = rbind(test_data, train_data)
save(full_data, file=MERGED_DATA)
write.table(full_data, file=MERGED_DATA_TXT, sep=',', row.names = FALSE)
View(full_data)
purl('run_analysis.Rmd')
View(tidy_data)
View(full_data)
mean_cols
tmp = dataframe(mean_cols)
tmp = data.frame(mean_cols)
View(tmp)
View(tmp)
purl('run_analysis.Rmd')
